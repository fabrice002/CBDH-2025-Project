import pandas as pd
import re
import numpy as np
from unidecode import unidecode
from thefuzz import fuzz, process
import numpy as np



def preprocess_eligibility_data(df):
    """
    Traite les donn√©es d'√©ligibilit√© au don en filtrant les non-√©ligibles,
    nettoyant les donn√©es et regroupant les raisons d'indisponibilit√©.
    """


    # 1Ô∏è‚É£ Suppression des colonnes inutiles
    cols_to_drop = ['Date de derni√®res r√®gles (DDR) ', 'S√©lectionner "ok" pour envoyer']
    df = df.drop(columns=cols_to_drop, errors='ignore')

    # 3Ô∏è‚É£ Remplacement des valeurs manquantes par 'Non'
    df= df.fillna('Non')

    # 4Ô∏è‚É£ Regroupement des raisons d'indisponibilit√©
    columns_mapping = {
            "Raison indisponibilit√©  [Taux d‚Äôh√©moglobine bas ]": "Taux d‚Äôh√©moglobine bas",
            "Raison indisponibilit√©  [date de dernier Don < 3 mois ]": "Date de dernier Don < 3 mois",
            "Raison indisponibilit√©  [Est sous anti-bioth√©rapie  ]": "Est sous anti-bioth√©rapie",
            "Raison indisponibilit√©  [IST r√©cente (Exclu VIH, Hbs, Hcv)]": "IST r√©cente (Exclu VIH, Hbs, Hcv)",
            "Raison de l‚Äôindisponibilit√© de la femme [La DDR est mauvais si <14 jour avant le don]": "La DDR < 14 jours",
            "Raison de l‚Äôindisponibilit√© de la femme [A accoucher ces 6 derniers mois  ]": "A accoucher ces 6 derniers mois",
            "Raison de l‚Äôindisponibilit√© de la femme [Allaitement ]": "Allaitement",
            "Raison de l‚Äôindisponibilit√© de la femme [Interruption de grossesse  ces 06 derniers mois]": "Interruption de grossesse ces 06 derniers mois",
            "Raison de l‚Äôindisponibilit√© de la femme [est enceinte ]": "Est enceinte",
            "Raison de non-eligibilit√© totale  [Ant√©c√©dent de transfusion]": "Ant√©c√©dent de transfusion",
            "Raison de non-eligibilit√© totale  [Porteur(HIV,hbs,hcv)]": "Porteur (HIV, Hbs, Hcv)",
            "Raison de non-eligibilit√© totale  [Op√©r√©]": "Op√©r√©",
            "Raison de non-eligibilit√© totale  [Drepanocytaire]": "Drepanocytaire",
            "Raison de non-eligibilit√© totale  [Diab√©tique]": "Diab√©tique",
            "Raison de non-eligibilit√© totale  [Hypertendus]": "Hypertendus",
            "Raison de non-eligibilit√© totale  [Asthmatiques]": "Asthmatiques",
            "Raison de non-eligibilit√© totale  [Cardiaque]": "Cardiaque",
            "Raison de non-eligibilit√© totale  [Tatou√©]": "Tatou√©",
            "Raison de non-eligibilit√© totale  [Scarifi√©]": "Scarifi√©" 
            
        }
    
    def combine(row):
        reason = []
        

        # V√©rification de chaque colonne
        for col, label in columns_mapping.items():
            if row.get(col, 'Non') != 'Non':
                reason.append(label)

        # Ajout des raisons personnalis√©es si renseign√©es
        if row.get('Si autres raison pr√©ciser', 'Non') != 'Non':
            reason.append(row['Si autres raison pr√©ciser'])
        if row.get("Autre raisons,  preciser", 'Non') != 'Non':
            reason.append(row["Autre raisons,  preciser"])

        return ', '.join(reason) if reason else "aucune"
    
    

    # Application de la fonction
    df['raison_indisponibilite'] = df.apply(combine, axis=1) 
    
    # 5Ô∏è‚É£ Suppression des colonnes inutiles apr√®s regroupement
    df = df.drop(columns=list(columns_mapping.keys()) + [
        'Si autres raison pr√©ciser', 'Autre raisons,  preciser'
    ], errors='ignore')
    
    return df




def normalize_dates(df, column_name):
    """
    Normalise les dates dans la colonne sp√©cifi√©e d'un DataFrame.
    
    √âtapes :
    1. Remplace les ann√©es incorrectes (ex: 0019) par 2019.
    2. Convertit les valeurs en datetime.
    3. Remplace toutes les ann√©es qui ne sont pas 2019 par 2019.

    :param df: DataFrame contenant la colonne de dates.
    :param column_name: Nom de la colonne √† traiter.
    :return: DataFrame avec la colonne normalis√©e.
    """
    
    # Fonction de nettoyage pour uniformiser les dates
    def clean_date(x):
        if isinstance(x, str):
            # Remplacer toute ann√©e de deux chiffres invalides par 2019
            x = re.sub(r'^\d{2}(?=\d{2})', '2019', x)  
            # Remplacer explicitement les cas avec '0019' par '2019'
            x = re.sub(r'(\d{1,2}/\d{1,2}/)0019', r'\g<1>2019', x)
        return x

    # Appliquer le nettoyage initial
    df[column_name] = df[column_name].apply(clean_date)

    # Convertir la colonne en datetime, avec gestion des erreurs
    df[column_name] = pd.to_datetime(df[column_name], errors='coerce')

    # Remplacer l'ann√©e par 2019 si elle n'est pas 2019
    df[column_name] = df[column_name].apply(lambda x: x.replace(year=2019) if pd.notna(x) and x.year != 2019 else x)
    
    df[column_name].fillna(df[column_name].mode()[0], inplace=True)

    return df

def clean_and_impute_age(df, date_col='Date de naissance', profession_col='Profession', ref_date='2019-12-31'):
    """
    Nettoie et impute la colonne 'age' :
    - Convertit 'Date de naissance' en datetime.
    - Calcule l'√¢ge en ann√©es √† partir de la date de r√©f√©rence.
    - Remplace les √¢ges aberrants (<15 ou >70) par NaN.
    - Remplace les NaN par la m√©diane des √¢ges de la m√™me profession.
    - Remplace les NaN restants par la m√©diane globale.
    - Convertit la colonne 'age' en entier.

    :param df: DataFrame contenant les colonnes 'Date de naissance' et 'Profession'
    :param date_col: Nom de la colonne contenant les dates de naissance
    :param profession_col: Nom de la colonne contenant la profession
    :param ref_date: Date de r√©f√©rence pour le calcul de l'√¢ge
    :return: DataFrame mis √† jour avec une colonne 'age' en entier
    """
    
    # Convertir la colonne 'Date de naissance' en format datetime
    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')

    # D√©finir la date de r√©f√©rence
    date_reference = pd.Timestamp(ref_date)

    # Calcul de l'√¢ge
    df['age'] = (date_reference - df[date_col]).dt.days // 365.25

    # Filtrer les √¢ges aberrants
    df.loc[(df['age'] < 15) | (df['age'] > 70) | (df['age'].isna()), 'age'] = np.nan

    # Calculer la m√©diane des √¢ges par profession
    mean_age_by_profession = df.groupby(profession_col)['age'].median()

    # Remplacer les NaN dans 'age' par la m√©diane de la profession
    df.loc[df['age'].isna(), 'age'] = df.loc[df['age'].isna(), profession_col].map(mean_age_by_profession)

    # Remplacer les NaN restants par la m√©diane globale
    df['age'].fillna(df['age'].median(), inplace=True)

    # Convertir en entier
    df['age'] = df['age'].astype(int)

    return df



def normaliser_ras(valeur):
        """ Regroupe toutes les variations de 'RAS' en une seule valeur standardis√©e. """
        patterns_ras = [
            r'(?i)^\s*(R[\s.]*A[\s.]*S|Rien|Aucun|Non pr√©cis√©|Pas pr√©cis√©|Pas mentionn√©)|Non precis√©|Pas precise\s*$'
        ]
        return 'RAS' if any(re.match(pattern, valeur) for pattern in patterns_ras) else valeur.strip()
def normalize_quarter_name(name):
        """ Nettoie et uniformise les noms de quartiers. """
        name = unidecode(str(name)).upper().strip()
        name = re.sub(r'[^A-Z0-9 ]', '', name)  # Supprime caract√®res sp√©ciaux
        return re.sub(r'\s+', ' ', name)  # Supprime espaces multiples
    
def imputer_poids(data):
    if pd.isna(data['Poids']):  # V√©rifie si la valeur est manquante
        if data['√âLIGIBILIT√â AU DON.'] == 'Eligible':
            return np.random.randint(60, 100)  # Poids entre 60 et 150
        else: 
            return np.nan
    return data['Poids']

def imputer_tauxhemoglobine(data):
    if pd.isna(data['Taux d‚Äôh√©moglobine']):  # V√©rifie si la valeur est manquante
        if data['Genre'] == 'Homme':
            if data['√âLIGIBILIT√â AU DON.'] == 'Temporairement Non-eligible':
                return np.random.uniform(6, 13)  # Valeur al√©atoire entre 6 et 13
            elif data['√âLIGIBILIT√â AU DON.'] == 'Eligible' :
                return np.random.uniform(13, 18)
            else: 
                return np.nan
        else:  # Femme
            if data['√âLIGIBILIT√â AU DON.'] == 'Temporairement Non-eligible':
                return np.random.uniform(5, 12)  # Valeur al√©atoire entre 5 et 12
            elif data['√âLIGIBILIT√â AU DON.'] == 'Eligible' :
                return np.random.uniform(12, 18)
            else:  
                return np.nan
    return data['Taux d‚Äôh√©moglobine']

    

def nettoyer_donnees(df, seuil_similarite_quartier=85, seuil_similarite_profession=85):
    """
    Pipeline complet de nettoyage et correction des donn√©es :
    
    1Ô∏è‚É£ Nettoyage des valeurs manquantes et normalisation des valeurs RAS
    2Ô∏è‚É£ Normalisation et regroupement des quartiers (fuzzy matching)
    3Ô∏è‚É£ Correction et standardisation des arrondissements
    4Ô∏è‚É£ Harmonisation des nationalit√©s
    5Ô∏è‚É£ Classification des religions
    6Ô∏è‚É£ Regroupement et standardisation des professions (fuzzy matching)
    7Ô∏è‚É£ Imputation des valeurs manquantes (Taille, Poids, Taux d‚Äôh√©moglobine)
    8Ô∏è‚É£ Traitement des donn√©es d‚Äô√©ligibilit√© au don
    9Ô∏è‚É£ Nettoyage et imputation de l‚Äô√¢ge
    üîü Suppression des colonnes inutiles
    1Ô∏è‚É£1Ô∏è‚É£ Normalisation des dates
    """
    
     # Fixer la seed pour la reproductibilit√© des r√©sultats
    np.random.seed(42)
    
    # 1Ô∏è‚É£ Nettoyage des valeurs manquantes et normalisation des RAS
    colonnes_a_normaliser = ['Nationalit√©', 'Religion', 'Quartier de R√©sidence', 'Arrondissement de r√©sidence']
    for col in colonnes_a_normaliser:
        df[col] = df[col].astype(str).apply(normaliser_ras)
    
    # 2Ô∏è‚É£ Normalisation des noms de quartiers
    df['Quartier de R√©sidence'] = df['Quartier de R√©sidence'].apply(normalize_quarter_name)
    
    # 3Ô∏è‚É£ Regroupement des quartiers similaires (Fuzzy Matching)
    quartiers_uniques = {}

    def trouver_nom_canonique(nom):
        if not quartiers_uniques:
            quartiers_uniques[nom] = nom
            return nom
        match, score = process.extractOne(nom, quartiers_uniques.keys(), scorer=fuzz.token_sort_ratio)
        return quartiers_uniques[match] if score >= seuil_similarite_quartier else quartiers_uniques.setdefault(nom, nom)

    df['Quartier de R√©sidence'] = df['Quartier de R√©sidence'].apply(trouver_nom_canonique)
    
    # 4Ô∏è‚É£ Correction et standardisation des arrondissements
    normalization_dict = {
        r'(?i)^\s*Deido\s*$': 'Douala 1',
        r'(?i)^\s*(Ngodi Bakoko|OYACK|BOKO)\s*$': 'Douala 3',
        r'(?i)^\s*(Yaound[e√©]|Nkouabang)\s*$': 'Yaound√©',
        r'(?i)^\s*BUEA\s*$': 'Buea',
        r'(?i)^\s*Bafoussam\s*$': 'Bafoussam',
        r'(?i)^\s*TIKO\s*$': 'Tiko',
        r'(?i)^\s*LIMBE\s*$': 'Limbe'
    }
    df['Arrondissement de r√©sidence'] = df['Arrondissement de r√©sidence'].replace(normalization_dict, regex=True)

    # Correction des valeurs erron√©es en utilisant l'arrondissement majoritaire du quartier
    valeurs_erronees = {'Douala (Non pr√©cis√© )', 'Douala 6'}
    arrondissements_majoritaires = df.loc[~df['Arrondissement de r√©sidence'].isin(valeurs_erronees)] \
        .groupby('Quartier de R√©sidence')['Arrondissement de r√©sidence'] \
        .agg(lambda x: x.mode()[0] if not x.mode().empty else None) \
        .dropna().to_dict()
    
    df.loc[df['Arrondissement de r√©sidence'].isin(valeurs_erronees), 'Arrondissement de r√©sidence'] = \
        df['Quartier de R√©sidence'].map(arrondissements_majoritaires).fillna(df['Arrondissement de r√©sidence'])
    
    # 5Ô∏è‚É£ Normalisation des nationalit√©s
    nationalite_dict = {
        'Centrafricaine': 'CENTRAFRICAINE',
        'Malien': 'MALIEN',
        'Malienne': 'MALIEN',
        'AMERICAINE': 'AM√âRICAINE',
        'Tchadienne': 'TCHADIENNE'
    }
    df['Nationalit√©'] = df['Nationalit√©'].replace(nationalite_dict)

    # 6Ô∏è‚É£ Classification des religions
    conditions = [
        df['Religion'].str.contains(r'(?i)chr[e√©]tien|baptist|presbyt[e√©]rien|pentec[o√¥]tiste|adventiste|epc|cmci|uebc|croyant|pantecotiste', na=False),
        df['Religion'].str.contains(r'(?i)musulman', na=False),
        df['Religion'].str.contains(r'(?i)non\s*croyant|la[i√Ø]c|aucune|r\s*a\s*s|lo[i√Ø]c|non\s*pr[e√©]cis[e√©]', na=False),
        df['Religion'].str.contains(r'(?i)animiste|traditionaliste|crois en tout|loique', na=False)
    ]
    categories = ['CHRETIEN', 'MUSULMAN', 'NON-RELIGIEUX', 'AUTRES']
    df['Religion'] = np.select(conditions, categories, default='RAS')
    
    # 7Ô∏è‚É£ Normalisation et regroupement des professions
    def normalize_profession(profession):
        profession = unidecode(str(profession)).upper().strip()
        profession = re.sub(r'[^A-Z0-9 ]', '', profession)
        return re.sub(r'\s+', ' ', profession)
    
    df['Profession'] = df['Profession'].astype(str).str.strip()
    patterns_no_profession = [r'^\s*AUCUN\s*$', r'^\s*RIEN\s*$', r'^\s*SANS\s*$', r'^\s*PAS DE PROFESSION\s*$']
    df['Profession'].replace('|'.join(patterns_no_profession), 'SANS PROFESSION', regex=True, inplace=True)
    df['Profession'] = df['Profession'].apply(normalize_profession)
    
    def regrouper_professions(df, colonne, seuil_similarite):
        professions_uniques = {}
        def trouver_nom_canonique(nom):
            if not professions_uniques:
                professions_uniques[nom] = nom
                return nom
            match, score = process.extractOne(nom, professions_uniques.keys(), scorer=fuzz.token_sort_ratio)
            return professions_uniques[match] if score >= seuil_similarite else professions_uniques.setdefault(nom, nom)
        
        df[colonne] = df[colonne].apply(trouver_nom_canonique)
        return df
    
    df = regrouper_professions(df, 'Profession', seuil_similarite_profession)
    
    # 8Ô∏è‚É£ Imputation des valeurs manquantes pour Taille, Poids et Taux d‚Äôh√©moglobine
    df['Taille'] = df['Taille'].apply(lambda x: np.random.uniform(1.5, 2) if pd.isna(x) else x)
    df.loc[df['Taille'] >= 3, 'Taille'] /= 100  # Conversion des tailles en m√®tres
    # df.loc[(df['Taille'] >= 3), 'Taille'] = np.nan
    # df['Taille'] = df['Taille'].fillna(df['Taille'].median())

    df['Taux d‚Äôh√©moglobine'] = df.apply(imputer_tauxhemoglobine, axis=1)

    df['Poids'] = df.apply(imputer_poids, axis=1) 
    df['Poids'] = df['Poids'].astype(float)
    
    #  Calcul de la moyenne des poids par arrondissement (en ignorant les NaN)
    mediane_par_arr = df.groupby('Arrondissement de r√©sidence')['Poids'].median()

    def remplacer_par_mediane(row):
        if pd.isna(row['Poids']):
            return mediane_par_arr.get(row['Arrondissement de r√©sidence'], np.nan)
        return row['Poids']

    df['Poids'] = df.apply(remplacer_par_mediane, axis=1)
    df['Poids'] = df['Poids'].fillna(df['Poids'].median())  # Remplacer les NaN restants par la m√©diane globale

    
    df['Taux d‚Äôh√©moglobine'] = df['Taux d‚Äôh√©moglobine'].astype(str).str.replace(',', '.').str.extract(r'(\d+\.?\d*)').astype(float)
    df.loc[df['Taux d‚Äôh√©moglobine'] > 20, 'Taux d‚Äôh√©moglobine'] /= 10  # Valeurs aberrantes
    
    mediane_hemo_par_arr = df.groupby('Arrondissement de r√©sidence')['Taux d‚Äôh√©moglobine'].median()

    # Fonction pour imputer le taux d'h√©moglobine avec la m√©diane de l'arrondissement
    def imputer_hemo(row):
        if pd.isna(row['Taux d‚Äôh√©moglobine']):
            return mediane_hemo_par_arr.get(row['Arrondissement de r√©sidence'], np.nan)
        return row['Taux d‚Äôh√©moglobine']

    # Appliquer l'imputation sur les valeurs manquantes
    df['Taux d‚Äôh√©moglobine'] = df.apply(imputer_hemo, axis=1)

    # 9Ô∏è‚É£ Traitement des donn√©es d'√©ligibilit√© au don
    df = preprocess_eligibility_data(df)
    
    # üîü Nettoyage et imputation de l'√¢ge
    df = clean_and_impute_age(df)
    
    # 1Ô∏è‚É£1Ô∏è‚É£ Suppression des colonnes inutiles
    df.drop(columns=['Si oui preciser la date du dernier don.', 'Date de naissance'], errors='ignore', inplace=True)
    
    # 1Ô∏è‚É£2Ô∏è‚É£ Normalisation des dates
    df = normalize_dates(df, 'Date de remplissage de la fiche')
    df.columns = df.columns.str.replace(" ", "_")

    return df